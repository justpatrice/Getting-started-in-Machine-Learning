{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Basics of the method\n",
    "\n",
    "This is an iterative method for approximating the solution at optimizing a function. Say we have the function,\n",
    "\n",
    "$$ y = w_0 + w_1x_1 + w_2x_2 + \\dots + w_kx_k $$\n",
    "\n",
    "and we make a prediction such as \n",
    "\n",
    "$$ \\hat{y} = \\hat{w_0} + \\hat{w_1}x_1 + \\hat{w_2}x_2 + \\dots + \\hat{w_k}x_k $$\n",
    "\n",
    "This is the regression problem we studied back in Week 3\n",
    "\n",
    "The method starts with an initial value for each coefficient $\\hat{w_i}$ and a prediction $\\hat{y}$ is made. \n",
    "\n",
    "An *error*, $e$, is computed as $e = \\hat{y} - y$ and then each coefficient is updated, for this particular problem, in a new step like:\n",
    "\n",
    "$$\\hat{w_i}[t+1] = \\hat{w_i}[t] - l*e*x_i[t]$$\n",
    "\n",
    "The parameter $l$ is a small chosen constant referred to as *learning factor*. This procedure is repeated for each observation of the training dataset. If at the end of this process the error is still not close enough to zero, we repeat the whole process again, for a number of times or *epochs*.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's demo with a small amount of data (x, y) of values \n",
    "smalldata = np.array([[1, 1], [2, 3], [4, 3], [3, 2], [5, 5]]) \n",
    "data = pd.DataFrame(smalldata, columns=['x1', 'y'])\n",
    "print (data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a Plot is like\n",
    "sns.regplot('x1', 'y', data=data, fit_reg=False)\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that the above 5 points tend to follow a linear trend of the kind $y = w_0 + w_1x$. So let's try to find the coefficient values $w_0, w_1$ that define the line\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's fix the shape of our data\n",
    "\n",
    "In general,\n",
    "\n",
    "$$ y = w_0 + w_1x_1 + w_2x_2 + \\dots + w_kx_k $$\n",
    "\n",
    "This equation is normally written as:\n",
    "\n",
    "$$y = w_0 + \\begin{bmatrix}w_1 & w_2 &\\dots & w_k\\end{bmatrix} \\begin{bmatrix}x_1 \\\\ x_2\\\\ \\dots \\\\x_k \\end{bmatrix} $$\n",
    "\n",
    "And this can be re-arranged by inserting coefficient $w_0$ inside the matrix $W$ and augmenting feature $X$ with a constant of 1. Like so,\n",
    "\n",
    "$$y = \\begin{bmatrix}w_0 & w_1 & w_2 &\\dots & w_k\\end{bmatrix} \\begin{bmatrix}1 \\\\ x_1 \\\\ x_2\\\\ \\dots \\\\x_k \\end{bmatrix} $$\n",
    "\n",
    "This equation above is for a simple observation. \n",
    "\n",
    "The above equation is what most books write as: $y = W^TX$. We prefer to arrange $X$ where each row is an observation and each column is a feature so $X$ looks like a matrix. \n",
    "\n",
    "We need to augment our data to have $x_0$ column made of ones for our problem. Let's see how. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adding a column with constant ones\n",
    "data['x0'] = 1\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's change the order of our columns\n",
    "data = data[['x0', 'x1', 'y']]\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preparing our data with features and target\n",
    "X = data.drop(['y'], axis=1)\n",
    "y = data['y']\n",
    "X"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's put the method in Python code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# An initial guess for W, say of zero\n",
    "W = pd.DataFrame(np.zeros(2).reshape(1, 2), columns = ['w0', 'w1']) # This is stored as a vector \n",
    "\n",
    "print ('Initial weights', W)\n",
    "\n",
    "# A small constant learning factor\n",
    "l = 0.001\n",
    "\n",
    "# An arbitrary number of epochs\n",
    "P = 100\n",
    "\n",
    "# The gradient descent algorithm\n",
    "for t in range(P):                   # The number of epochs\n",
    "    for i in range(5):               # Visit all five points per epoch\n",
    "        yp = np.dot(W.values, X.iloc[i].values )     # prediction\n",
    "        e = yp - y[i]                                # error\n",
    "        W = W - l*e*X.iloc[i].values                 # update of weights\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final weights\n",
    "W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's plot what we got\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xtest = np.linspace(0, 8, 100)\n",
    "ytest = W['w0'].values + W['w1'].values*xtest\n",
    "\n",
    "sns.regplot('x1', 'y', data=data, fit_reg=True)\n",
    "sns.lineplot(xtest, ytest )\n",
    "plt.xlabel('x')\n",
    "plt.ylabel('y');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the blue line is the one painted by Seaborn using regression as computed in Week 3. The orange line is the one we have learned from Stochastic Gradient Descent method. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot the error as we advance through the epochs "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# An initial guess for W, say of zero\n",
    "W = pd.DataFrame(np.zeros(2).reshape(1, 2), columns = ['w0', 'w1']) # This is stored as a vector \n",
    "\n",
    "# A small constant learning factor\n",
    "l = 0.001\n",
    "\n",
    "# An arbitrary number of epochs\n",
    "P = 100\n",
    "\n",
    "error_history = np.zeros(P)\n",
    "\n",
    "# The gradient descent algorithm\n",
    "for t in range(P):                    # The number of epochs\n",
    "    for i in range(5):                # Visit all five points per epoch\n",
    "        yp = np.dot(W.values, X.iloc[i].values )     # prediction\n",
    "        e = yp - y[i]                                # error\n",
    "        W = W - l*e*X.iloc[i].values                 # update of weights\n",
    "    error_history[t] = e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.lineplot(np.arange(P), error_history )\n",
    "plt.ylim(-5,0)\n",
    "plt.title('Error reduction by epoch with SGD')\n",
    "plt.xlabel('epochs')\n",
    "plt.ylabel('error');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that keeping the data as a Pandas data frame makes the code a little cumbersome. In next examples we'll keep the computations as numpy arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
